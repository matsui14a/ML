{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # import numpy\n",
    "import pandas as pd # import pandas\n",
    "import zipfile # import 解zip壓縮檔\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "folders='/home/jovyan/at082-group10/nathan/For_AIA_0916_1018_Sample'\n",
    "all_data=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all csv data\n",
    "for folders in glob.glob('/home/jovyan/at082-group10/nathan/For_AIA_0916_1018_Sample/IP*/*'):\n",
    "    for file in glob.glob(folders+'/FeatureNEW/'):\n",
    "        \n",
    "        for filename in os.listdir(file):\n",
    "            if (os.path.splitext(filename)[-1]=='.csv'): # only read 副檔為csv\n",
    "                #print(os.path.join(file,filename))\n",
    "                #print(file.split('/')[7])\n",
    "                if(file.split('/')[6]=='IP17' or file.split('/')[6]=='IP18' or file.split('/')[6]=='IP19'):\n",
    "                    \n",
    "                    temp_pd=pd.read_csv(os.path.join(file,filename))\n",
    "                    temp_pd.insert(0,column=\"machiine\",value=file.split('/')[6]) # 新增機台欄位\n",
    "                    if(all_data is None):\n",
    "                        all_data=temp_pd\n",
    "                    else :\n",
    "                        all_data=pd.concat([all_data,temp_pd],axis=0, ignore_index=True)\n",
    "            else :\n",
    "                next\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_t=[]\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "for i in range(len(all_data)):\n",
    "    if (datetime.strptime((all_data['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-16 04:00',\"%Y-%m-%d %H:%M\")>timedelta(minutes=0)):\n",
    "        if(all_data['machiine'][i]=='IP17'):\n",
    "            la_t.append('1')\n",
    "        else:\n",
    "            la_t.append('0')\n",
    "    else:\n",
    "        la_t.append('0')\n",
    "        \n",
    "#all_data=pd.concat([all_data,la_t],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(la_t, columns = ['lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.concat([all_data,df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame()\n",
    "temp_pd2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all csv data\n",
    "for folders in glob.glob('/home/jovyan/at082-group10/For_AIA_1019_1029/IP*/*'):\n",
    "    #print(\"1\")\n",
    "    for file in glob.glob(folders+'/FeatureNEW/'):\n",
    "        #print('2')\n",
    "        for filename in os.listdir(file):\n",
    "            #print('3')\n",
    "            if (os.path.splitext(filename)[-1]=='.csv'): # only read 副檔為csv\n",
    "                #print('4')\n",
    "                #print(os.path.join(file,filename))\n",
    "                #print(file.split('/')[7])\n",
    "               \n",
    "                if(file.split('/')[5]=='IP17' or file.split('/')[5]=='IP18' or file.split('/')[5]=='IP19'):\n",
    "                    #print('5')\n",
    "                    temp_pd2=pd.read_csv(os.path.join(file,filename))\n",
    "                    temp_pd2.insert(0,column=\"machiine\",value=file.split('/')[5]) # 新增機台欄位\n",
    "                    \n",
    "                    if(test is None):\n",
    "                        test=temp_pd2\n",
    "                    else :\n",
    "                        test=pd.concat([test,temp_pd2],axis=0, ignore_index=True)\n",
    "            else :\n",
    "                next\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_t=[]\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "for i in range(len(test)):\n",
    "    if(test['machiine'][i]=='IP17'):\n",
    "        if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 15:00',\"%Y-%m-%d %H:%M\")>timedelta(minutes=0)):\n",
    "            if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 17:11',\"%Y-%m-%d %H:%M\")<timedelta(minutes=0)):\n",
    "                la_t.append('1')\n",
    "            else:\n",
    "                 la_t.append('0')\n",
    "        else:\n",
    "             la_t.append('0')\n",
    "    elif (test['machiine'][i]=='IP18'):\n",
    "        if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 11:00',\"%Y-%m-%d %H:%M\")>timedelta(minutes=0)):\n",
    "                if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 13:40',\"%Y-%m-%d %H:%M\")<timedelta(minutes=0)):\n",
    "                    la_t.append('1')\n",
    "                else:\n",
    "                    la_t.append('0')\n",
    "        else:\n",
    "             la_t.append('0')\n",
    "    else:\n",
    "        if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 11:16',\"%Y-%m-%d %H:%M\")>timedelta(minutes=0)):\n",
    "            if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 14:32',\"%Y-%m-%d %H:%M\")<timedelta(minutes=0)):\n",
    "                 la_t.append('1')\n",
    "            else:\n",
    "                 la_t.append('0')\n",
    "        else:\n",
    "               la_t.append('0')\n",
    "            \n",
    "     #test=pd.concat([test,la_t],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(la_t, columns = ['lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.concat([test,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17=all_data[all_data['machiine']=='IP17']\n",
    "IP18=all_data[all_data['machiine']=='IP18']\n",
    "IP19=all_data[all_data['machiine']=='IP19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17_FOURIER=IP17.iloc[:,63:]\n",
    "IP18_FOURIER=IP18.iloc[:,63:]\n",
    "IP19_FOURIER=IP19.iloc[:,63:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17t=test[test['machiine']=='IP17']\n",
    "IP18t=test[test['machiine']=='IP18']\n",
    "IP19t=test[test['machiine']=='IP19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17t_FOURIER=IP17t.iloc[:,63:]\n",
    "IP18t_FOURIER=IP18t.iloc[:,63:]\n",
    "IP19t_FOURIER=IP19t.iloc[:,63:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t7=IP17t_FOURIER.drop(columns='lab')\n",
    "y_t7=IP17t_FOURIER['lab']\n",
    "X_t8=IP18t_FOURIER.drop(columns='lab')\n",
    "y_t8=IP18t_FOURIER['lab']\n",
    "X_t9=IP19t_FOURIER.drop(columns='lab')\n",
    "y_t9=IP19t_FOURIER['lab']\n",
    "X_7=IP17_FOURIER.drop(columns='lab')\n",
    "y_7=IP17_FOURIER['lab']\n",
    "X_8=IP18_FOURIER.drop(columns='lab')\n",
    "y_8=IP18_FOURIER['lab']\n",
    "X_9=IP19_FOURIER.drop(columns='lab')\n",
    "y_9=IP19_FOURIER['lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17_nan=IP17.iloc[:,3:63]\n",
    "IP18_nan=IP18.iloc[:,3:63]\n",
    "IP19_nan=IP19.iloc[:,3:63]\n",
    "IP17t_nan=IP17t.iloc[:,3:63]\n",
    "IP18t_nan=IP18t.iloc[:,3:63]\n",
    "IP19t_nan=IP19t.iloc[:,3:63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.concat([y_7,y_8,y_9,y_t7,y_t8,y_t9],axis=0)\n",
    "X=pd.concat([X_7,X_8,X_9,X_t7,X_t8,X_t9],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X, y, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def xg_f1(y,t):\n",
    "    t = t.get_label()\n",
    "    y_bin = [1. if y_cont > 0.5 else 0. for y_cont in y] # binaryzing your output\n",
    "    return 'f1',f1_score(t,y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all 全頻遇XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.976416\tvalid-auc:0.931618\n",
      "[1]\ttrain-auc:0.989924\tvalid-auc:0.895813\n",
      "[2]\ttrain-auc:0.995245\tvalid-auc:0.916316\n",
      "[3]\ttrain-auc:0.997907\tvalid-auc:0.926836\n",
      "[4]\ttrain-auc:0.9995\tvalid-auc:0.92514\n",
      "[5]\ttrain-auc:0.999959\tvalid-auc:0.93597\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.936417\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.936572\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.939044\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.943182\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19935 fp:   354\n",
      "fn:   354 tp:   212\n",
      "\n",
      "*** better f-score 0.37455830388692585\n",
      "max_depth :  20  colsample_bytree :  0.8  eta :  0.5  \n",
      "\n",
      "[0]\ttrain-auc:0.975408\tvalid-auc:0.925342\n",
      "[1]\ttrain-auc:0.989002\tvalid-auc:0.897126\n",
      "[2]\ttrain-auc:0.993544\tvalid-auc:0.919314\n",
      "[3]\ttrain-auc:0.996168\tvalid-auc:0.939616\n",
      "[4]\ttrain-auc:0.998119\tvalid-auc:0.939807\n",
      "[5]\ttrain-auc:0.999233\tvalid-auc:0.943797\n",
      "[6]\ttrain-auc:0.99961\tvalid-auc:0.943787\n",
      "[7]\ttrain-auc:0.999946\tvalid-auc:0.942692\n",
      "[8]\ttrain-auc:0.999998\tvalid-auc:0.943533\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.94659\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19720 fp:   569\n",
      "fn:   275 tp:   291\n",
      "\n",
      "*** better f-score 0.40813464235624125\n",
      "max_depth :  20  colsample_bytree :  0.9  eta :  0.3  \n",
      "\n",
      "[0]\ttrain-auc:0.977425\tvalid-auc:0.926228\n",
      "[1]\ttrain-auc:0.991322\tvalid-auc:0.887201\n",
      "[2]\ttrain-auc:0.996587\tvalid-auc:0.910861\n",
      "[3]\ttrain-auc:0.998994\tvalid-auc:0.922147\n",
      "[4]\ttrain-auc:0.999804\tvalid-auc:0.927341\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.925493\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.930781\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.940117\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.942821\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.943658\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19963 fp:   326\n",
      "fn:   362 tp:   204\n",
      "\n",
      "[0]\ttrain-auc:0.985936\tvalid-auc:0.915555\n",
      "[1]\ttrain-auc:0.996149\tvalid-auc:0.861919\n",
      "[2]\ttrain-auc:0.998735\tvalid-auc:0.88891\n",
      "[3]\ttrain-auc:0.999659\tvalid-auc:0.911851\n",
      "[4]\ttrain-auc:0.999902\tvalid-auc:0.9316\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.935773\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.943474\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.947075\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.952578\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.954943\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 20036 fp:   253\n",
      "fn:   405 tp:   161\n",
      "\n",
      "[0]\ttrain-auc:0.974826\tvalid-auc:0.923615\n",
      "[1]\ttrain-auc:0.990014\tvalid-auc:0.903731\n",
      "[2]\ttrain-auc:0.993663\tvalid-auc:0.923784\n",
      "[3]\ttrain-auc:0.996525\tvalid-auc:0.933196\n",
      "[4]\ttrain-auc:0.997912\tvalid-auc:0.946831\n",
      "[5]\ttrain-auc:0.999311\tvalid-auc:0.950097\n",
      "[6]\ttrain-auc:0.999788\tvalid-auc:0.953218\n",
      "[7]\ttrain-auc:0.999935\tvalid-auc:0.954856\n",
      "[8]\ttrain-auc:0.999991\tvalid-auc:0.955639\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.956256\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19696 fp:   593\n",
      "fn:   273 tp:   293\n",
      "\n",
      "[0]\ttrain-auc:0.979892\tvalid-auc:0.931172\n",
      "[1]\ttrain-auc:0.992295\tvalid-auc:0.897568\n",
      "[2]\ttrain-auc:0.995812\tvalid-auc:0.918691\n",
      "[3]\ttrain-auc:0.998189\tvalid-auc:0.933652\n",
      "[4]\ttrain-auc:0.999208\tvalid-auc:0.939959\n",
      "[5]\ttrain-auc:0.99968\tvalid-auc:0.946293\n",
      "[6]\ttrain-auc:0.999879\tvalid-auc:0.948295\n",
      "[7]\ttrain-auc:0.999929\tvalid-auc:0.948325\n",
      "[8]\ttrain-auc:0.99999\tvalid-auc:0.952507\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.953595\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19796 fp:   493\n",
      "fn:   307 tp:   259\n",
      "\n",
      "[0]\ttrain-auc:0.978527\tvalid-auc:0.91469\n",
      "[1]\ttrain-auc:0.992468\tvalid-auc:0.886929\n",
      "[2]\ttrain-auc:0.996158\tvalid-auc:0.905825\n",
      "[3]\ttrain-auc:0.998056\tvalid-auc:0.913117\n",
      "[4]\ttrain-auc:0.998981\tvalid-auc:0.926189\n",
      "[5]\ttrain-auc:0.999741\tvalid-auc:0.935679\n",
      "[6]\ttrain-auc:0.999892\tvalid-auc:0.935789\n",
      "[7]\ttrain-auc:0.999985\tvalid-auc:0.938703\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.940322\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.943407\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19797 fp:   492\n",
      "fn:   295 tp:   271\n",
      "\n",
      "[0]\ttrain-auc:0.970976\tvalid-auc:0.911673\n",
      "[1]\ttrain-auc:0.989744\tvalid-auc:0.885544\n",
      "[2]\ttrain-auc:0.994111\tvalid-auc:0.912707\n",
      "[3]\ttrain-auc:0.997332\tvalid-auc:0.921259\n",
      "[4]\ttrain-auc:0.998522\tvalid-auc:0.930677\n",
      "[5]\ttrain-auc:0.999317\tvalid-auc:0.933791\n",
      "[6]\ttrain-auc:0.999795\tvalid-auc:0.942141\n",
      "[7]\ttrain-auc:0.99993\tvalid-auc:0.943128\n",
      "[8]\ttrain-auc:0.999994\tvalid-auc:0.948939\n",
      "[9]\ttrain-auc:0.999999\tvalid-auc:0.952126\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19713 fp:   576\n",
      "fn:   285 tp:   281\n",
      "\n",
      "[0]\ttrain-auc:0.977425\tvalid-auc:0.926228\n",
      "[1]\ttrain-auc:0.98739\tvalid-auc:0.908614\n",
      "[2]\ttrain-auc:0.993038\tvalid-auc:0.9223\n",
      "[3]\ttrain-auc:0.995863\tvalid-auc:0.931736\n",
      "[4]\ttrain-auc:0.997712\tvalid-auc:0.941096\n",
      "[5]\ttrain-auc:0.999064\tvalid-auc:0.941216\n",
      "[6]\ttrain-auc:0.99961\tvalid-auc:0.940889\n",
      "[7]\ttrain-auc:0.999916\tvalid-auc:0.943229\n",
      "[8]\ttrain-auc:0.999988\tvalid-auc:0.945925\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.954125\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19715 fp:   574\n",
      "fn:   269 tp:   297\n",
      "\n",
      "*** better f-score 0.4133611691022964\n",
      "max_depth :  20  colsample_bytree :  1.0  eta :  0.3  \n",
      "\n",
      "[0]\ttrain-auc:0.98013\tvalid-auc:0.923734\n",
      "[1]\ttrain-auc:0.992855\tvalid-auc:0.858311\n",
      "[2]\ttrain-auc:0.997358\tvalid-auc:0.890905\n",
      "[3]\ttrain-auc:0.999068\tvalid-auc:0.913504\n",
      "[4]\ttrain-auc:0.999741\tvalid-auc:0.919713\n",
      "[5]\ttrain-auc:0.999964\tvalid-auc:0.922576\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.932155\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.93642\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.940077\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.944989\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19944 fp:   345\n",
      "fn:   359 tp:   207\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全時域資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.concat([y_7,y_8,y_9,y_t7,y_t8,y_t9],axis=0)\n",
    "X=pd.concat([IP17_nan,IP18_nan,IP19_nan,IP17t_nan,IP18t_nan,IP19t_nan],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X, y, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.976812\tvalid-auc:0.914704\n",
      "[1]\ttrain-auc:0.991433\tvalid-auc:0.839291\n",
      "[2]\ttrain-auc:0.998398\tvalid-auc:0.848763\n",
      "[3]\ttrain-auc:0.999897\tvalid-auc:0.855187\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.872662\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.888114\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.897326\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.904595\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.912843\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.919251\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19950 fp:   339\n",
      "fn:   432 tp:   134\n",
      "\n",
      "*** better f-score 0.2579403272377286\n",
      "max_depth :  30  colsample_bytree :  0.9  eta :  0.6  \n",
      "\n",
      "[0]\ttrain-auc:0.965359\tvalid-auc:0.911867\n",
      "[1]\ttrain-auc:0.981813\tvalid-auc:0.887868\n",
      "[2]\ttrain-auc:0.989731\tvalid-auc:0.886503\n",
      "[3]\ttrain-auc:0.995891\tvalid-auc:0.886372\n",
      "[4]\ttrain-auc:0.999245\tvalid-auc:0.892887\n",
      "[5]\ttrain-auc:0.999882\tvalid-auc:0.890531\n",
      "[6]\ttrain-auc:0.99994\tvalid-auc:0.899136\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.905616\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.913296\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.916245\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19838 fp:   451\n",
      "fn:   431 tp:   135\n",
      "\n",
      "[0]\ttrain-auc:0.971599\tvalid-auc:0.910574\n",
      "[1]\ttrain-auc:0.987014\tvalid-auc:0.882104\n",
      "[2]\ttrain-auc:0.995335\tvalid-auc:0.882972\n",
      "[3]\ttrain-auc:0.998364\tvalid-auc:0.880158\n",
      "[4]\ttrain-auc:0.999249\tvalid-auc:0.891575\n",
      "[5]\ttrain-auc:0.999839\tvalid-auc:0.896323\n",
      "[6]\ttrain-auc:0.999989\tvalid-auc:0.900521\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.898578\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.904444\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.910858\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19829 fp:   460\n",
      "fn:   416 tp:   150\n",
      "\n",
      "[0]\ttrain-auc:0.97037\tvalid-auc:0.915251\n",
      "[1]\ttrain-auc:0.98596\tvalid-auc:0.879655\n",
      "[2]\ttrain-auc:0.993334\tvalid-auc:0.883619\n",
      "[3]\ttrain-auc:0.997322\tvalid-auc:0.888872\n",
      "[4]\ttrain-auc:0.99948\tvalid-auc:0.878813\n",
      "[5]\ttrain-auc:0.999905\tvalid-auc:0.881668\n",
      "[6]\ttrain-auc:0.999982\tvalid-auc:0.892633\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.896714\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.901846\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.911291\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19808 fp:   481\n",
      "fn:   402 tp:   164\n",
      "\n",
      "*** better f-score 0.2708505367464905\n",
      "max_depth :  25  colsample_bytree :  0.9  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.979275\tvalid-auc:0.91509\n",
      "[1]\ttrain-auc:0.99506\tvalid-auc:0.856456\n",
      "[2]\ttrain-auc:0.999179\tvalid-auc:0.840433\n",
      "[3]\ttrain-auc:0.999951\tvalid-auc:0.85055\n",
      "[4]\ttrain-auc:0.999999\tvalid-auc:0.870228\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.885445\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.895403\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.906607\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.912732\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.917163\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19946 fp:   343\n",
      "fn:   447 tp:   119\n",
      "\n",
      "[0]\ttrain-auc:0.979275\tvalid-auc:0.91509\n",
      "[1]\ttrain-auc:0.988057\tvalid-auc:0.893102\n",
      "[2]\ttrain-auc:0.992981\tvalid-auc:0.895773\n",
      "[3]\ttrain-auc:0.998305\tvalid-auc:0.887346\n",
      "[4]\ttrain-auc:0.999339\tvalid-auc:0.899341\n",
      "[5]\ttrain-auc:0.999878\tvalid-auc:0.896817\n",
      "[6]\ttrain-auc:0.999989\tvalid-auc:0.897631\n",
      "[7]\ttrain-auc:0.999996\tvalid-auc:0.9025\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.912185\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.915493\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19766 fp:   523\n",
      "fn:   405 tp:   161\n",
      "\n",
      "[0]\ttrain-auc:0.971187\tvalid-auc:0.917786\n",
      "[1]\ttrain-auc:0.984036\tvalid-auc:0.897295\n",
      "[2]\ttrain-auc:0.989564\tvalid-auc:0.90393\n",
      "[3]\ttrain-auc:0.994596\tvalid-auc:0.890708\n",
      "[4]\ttrain-auc:0.998494\tvalid-auc:0.898835\n",
      "[5]\ttrain-auc:0.999532\tvalid-auc:0.89749\n",
      "[6]\ttrain-auc:0.999901\tvalid-auc:0.90674\n",
      "[7]\ttrain-auc:0.999986\tvalid-auc:0.907406\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.908426\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.90755\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19703 fp:   586\n",
      "fn:   362 tp:   204\n",
      "\n",
      "*** better f-score 0.3008849557522124\n",
      "max_depth :  25  colsample_bytree :  1.0  eta :  0.3  \n",
      "\n",
      "[0]\ttrain-auc:0.979275\tvalid-auc:0.91509\n",
      "[1]\ttrain-auc:0.991615\tvalid-auc:0.874751\n",
      "[2]\ttrain-auc:0.996739\tvalid-auc:0.863076\n",
      "[3]\ttrain-auc:0.999683\tvalid-auc:0.877001\n",
      "[4]\ttrain-auc:0.999986\tvalid-auc:0.887051\n",
      "[5]\ttrain-auc:0.999997\tvalid-auc:0.887693\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.900232\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.911642\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.919145\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.921427\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19911 fp:   378\n",
      "fn:   428 tp:   138\n",
      "\n",
      "[0]\ttrain-auc:0.964322\tvalid-auc:0.908571\n",
      "[1]\ttrain-auc:0.981899\tvalid-auc:0.866217\n",
      "[2]\ttrain-auc:0.989969\tvalid-auc:0.890108\n",
      "[3]\ttrain-auc:0.997829\tvalid-auc:0.887188\n",
      "[4]\ttrain-auc:0.99949\tvalid-auc:0.886728\n",
      "[5]\ttrain-auc:0.999936\tvalid-auc:0.892902\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.897312\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.901975\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.911889\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.913659\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19886 fp:   403\n",
      "fn:   419 tp:   147\n",
      "\n",
      "[0]\ttrain-auc:0.963695\tvalid-auc:0.912351\n",
      "[1]\ttrain-auc:0.979141\tvalid-auc:0.901695\n",
      "[2]\ttrain-auc:0.985277\tvalid-auc:0.902379\n",
      "[3]\ttrain-auc:0.993175\tvalid-auc:0.909697\n",
      "[4]\ttrain-auc:0.99642\tvalid-auc:0.910848\n",
      "[5]\ttrain-auc:0.99865\tvalid-auc:0.909706\n",
      "[6]\ttrain-auc:0.999147\tvalid-auc:0.916761\n",
      "[7]\ttrain-auc:0.999423\tvalid-auc:0.917891\n",
      "[8]\ttrain-auc:0.999846\tvalid-auc:0.924525\n",
      "[9]\ttrain-auc:0.999995\tvalid-auc:0.922433\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19515 fp:   774\n",
      "fn:   337 tp:   229\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=all_data.drop(columns=['machiine','lab'])\n",
    "y=all_data['lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X, y, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.963695\tvalid-auc:0.912351\n",
      "[1]\ttrain-auc:0.978903\tvalid-auc:0.900345\n",
      "[2]\ttrain-auc:0.986062\tvalid-auc:0.897024\n",
      "[3]\ttrain-auc:0.994753\tvalid-auc:0.895419\n",
      "[4]\ttrain-auc:0.997732\tvalid-auc:0.893568\n",
      "[5]\ttrain-auc:0.999527\tvalid-auc:0.896718\n",
      "[6]\ttrain-auc:0.999797\tvalid-auc:0.905435\n",
      "[7]\ttrain-auc:0.99995\tvalid-auc:0.908128\n",
      "[8]\ttrain-auc:0.999997\tvalid-auc:0.908194\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.911144\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19771 fp:   604\n",
      "fn:   292 tp:   188\n",
      "\n",
      "*** better f-score 0.29559748427672955\n",
      "max_depth :  20  colsample_bytree :  0.8  eta :  0.5  \n",
      "\n",
      "[0]\ttrain-auc:0.963695\tvalid-auc:0.912351\n",
      "[1]\ttrain-auc:0.979141\tvalid-auc:0.901695\n",
      "[2]\ttrain-auc:0.985277\tvalid-auc:0.902379\n",
      "[3]\ttrain-auc:0.993175\tvalid-auc:0.909697\n",
      "[4]\ttrain-auc:0.99642\tvalid-auc:0.910848\n",
      "[5]\ttrain-auc:0.99865\tvalid-auc:0.909706\n",
      "[6]\ttrain-auc:0.999147\tvalid-auc:0.916761\n",
      "[7]\ttrain-auc:0.999423\tvalid-auc:0.917891\n",
      "[8]\ttrain-auc:0.999846\tvalid-auc:0.924525\n",
      "[9]\ttrain-auc:0.999995\tvalid-auc:0.922433\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19601 fp:   774\n",
      "fn:   251 tp:   229\n",
      "\n",
      "*** better f-score 0.3088334457181389\n",
      "max_depth :  20  colsample_bytree :  0.8  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.971187\tvalid-auc:0.917786\n",
      "[1]\ttrain-auc:0.985616\tvalid-auc:0.883316\n",
      "[2]\ttrain-auc:0.991891\tvalid-auc:0.88614\n",
      "[3]\ttrain-auc:0.996866\tvalid-auc:0.89053\n",
      "[4]\ttrain-auc:0.999196\tvalid-auc:0.894971\n",
      "[5]\ttrain-auc:0.999829\tvalid-auc:0.899898\n",
      "[6]\ttrain-auc:0.999952\tvalid-auc:0.912646\n",
      "[7]\ttrain-auc:0.999999\tvalid-auc:0.912957\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.913615\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.915896\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19879 fp:   496\n",
      "fn:   308 tp:   172\n",
      "\n",
      "[0]\ttrain-auc:0.962645\tvalid-auc:0.905302\n",
      "[1]\ttrain-auc:0.981796\tvalid-auc:0.872036\n",
      "[2]\ttrain-auc:0.991798\tvalid-auc:0.888621\n",
      "[3]\ttrain-auc:0.997135\tvalid-auc:0.889642\n",
      "[4]\ttrain-auc:0.999404\tvalid-auc:0.889689\n",
      "[5]\ttrain-auc:0.999911\tvalid-auc:0.892638\n",
      "[6]\ttrain-auc:0.999988\tvalid-auc:0.902605\n",
      "[7]\ttrain-auc:0.999998\tvalid-auc:0.906903\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.916004\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.921865\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19923 fp:   452\n",
      "fn:   321 tp:   159\n",
      "\n",
      "[0]\ttrain-auc:0.962869\tvalid-auc:0.917526\n",
      "[1]\ttrain-auc:0.976772\tvalid-auc:0.907689\n",
      "[2]\ttrain-auc:0.984543\tvalid-auc:0.902785\n",
      "[3]\ttrain-auc:0.98847\tvalid-auc:0.909293\n",
      "[4]\ttrain-auc:0.993007\tvalid-auc:0.907436\n",
      "[5]\ttrain-auc:0.996785\tvalid-auc:0.913087\n",
      "[6]\ttrain-auc:0.998672\tvalid-auc:0.912504\n",
      "[7]\ttrain-auc:0.999342\tvalid-auc:0.921141\n",
      "[8]\ttrain-auc:0.999733\tvalid-auc:0.926672\n",
      "[9]\ttrain-auc:0.999835\tvalid-auc:0.930661\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19322 fp:  1053\n",
      "fn:   180 tp:   300\n",
      "\n",
      "*** better f-score 0.32733224222585927\n",
      "max_depth :  20  colsample_bytree :  1.0  eta :  0.3  \n",
      "\n",
      "[0]\ttrain-auc:0.96037\tvalid-auc:0.915084\n",
      "[1]\ttrain-auc:0.976059\tvalid-auc:0.903356\n",
      "[2]\ttrain-auc:0.985731\tvalid-auc:0.897596\n",
      "[3]\ttrain-auc:0.989628\tvalid-auc:0.895439\n",
      "[4]\ttrain-auc:0.993502\tvalid-auc:0.905089\n",
      "[5]\ttrain-auc:0.997509\tvalid-auc:0.910541\n",
      "[6]\ttrain-auc:0.998897\tvalid-auc:0.91417\n",
      "[7]\ttrain-auc:0.999522\tvalid-auc:0.916416\n",
      "[8]\ttrain-auc:0.999804\tvalid-auc:0.921766\n",
      "[9]\ttrain-auc:0.999975\tvalid-auc:0.921097\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19436 fp:   939\n",
      "fn:   239 tp:   241\n",
      "\n",
      "[0]\ttrain-auc:0.975294\tvalid-auc:0.909444\n",
      "[1]\ttrain-auc:0.991096\tvalid-auc:0.853024\n",
      "[2]\ttrain-auc:0.997009\tvalid-auc:0.867194\n",
      "[3]\ttrain-auc:0.999683\tvalid-auc:0.868469\n",
      "[4]\ttrain-auc:0.999957\tvalid-auc:0.870027\n",
      "[5]\ttrain-auc:0.999997\tvalid-auc:0.88443\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.889943\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.901833\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.909796\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.916341\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 20047 fp:   328\n",
      "fn:   357 tp:   123\n",
      "\n",
      "[0]\ttrain-auc:0.97037\tvalid-auc:0.915251\n",
      "[1]\ttrain-auc:0.982618\tvalid-auc:0.894289\n",
      "[2]\ttrain-auc:0.990437\tvalid-auc:0.891161\n",
      "[3]\ttrain-auc:0.994634\tvalid-auc:0.881948\n",
      "[4]\ttrain-auc:0.99775\tvalid-auc:0.902159\n",
      "[5]\ttrain-auc:0.998921\tvalid-auc:0.906542\n",
      "[6]\ttrain-auc:0.999505\tvalid-auc:0.908924\n",
      "[7]\ttrain-auc:0.999895\tvalid-auc:0.912976\n",
      "[8]\ttrain-auc:0.999983\tvalid-auc:0.912205\n",
      "[9]\ttrain-auc:0.999999\tvalid-auc:0.914864\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19678 fp:   697\n",
      "fn:   261 tp:   219\n",
      "\n",
      "[0]\ttrain-auc:0.979275\tvalid-auc:0.91509\n",
      "[1]\ttrain-auc:0.99506\tvalid-auc:0.856456\n",
      "[2]\ttrain-auc:0.999179\tvalid-auc:0.840433\n",
      "[3]\ttrain-auc:0.999951\tvalid-auc:0.85055\n",
      "[4]\ttrain-auc:0.999999\tvalid-auc:0.870228\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.885445\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.895403\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.906607\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.912732\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.917163\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 20032 fp:   343\n",
      "fn:   361 tp:   119\n",
      "\n",
      "[0]\ttrain-auc:0.979704\tvalid-auc:0.909323\n",
      "[1]\ttrain-auc:0.995082\tvalid-auc:0.846363\n",
      "[2]\ttrain-auc:0.998369\tvalid-auc:0.857571\n",
      "[3]\ttrain-auc:0.999902\tvalid-auc:0.85573\n",
      "[4]\ttrain-auc:0.999999\tvalid-auc:0.856461\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.886521\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.898002\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.909437\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.91895\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.920504\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 20078 fp:   297\n",
      "fn:   367 tp:   113\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=pd.concat([y_7,y_8,y_t7,y_t8],axis=0) #頻率 train 17、18 test 19\n",
    "X1=pd.concat([X_7,X_8,X_t7,X_t8],axis=0)\n",
    "y2=pd.concat([y_7,y_9,y_t7,y_t9],axis=0)\n",
    "X2=pd.concat([X_7,X_9,X_t7,X_t9],axis=0)\n",
    "y3=pd.concat([y_8,y_9,y_t8,y_t9],axis=0)\n",
    "X3=pd.concat([X_8,X_9,X_t8,X_t9],axis=0)\n",
    "y4=pd.concat([y_7,y_8,y_t7,y_t8],axis=0)\n",
    "X4=pd.concat([IP17_nan,IP18_nan,IP17t_nan,IP18t_nan],axis=0)\n",
    "y5=pd.concat([y_7,y_9,y_t7,y_t9],axis=0)\n",
    "X5=pd.concat([IP17_nan,IP19_nan,IP17t_nan,IP19t_nan],axis=0)\n",
    "y6=pd.concat([y_8,y_9,y_t8,y_t9],axis=0)\n",
    "X6=pd.concat([IP18_nan,IP19_nan,IP18t_nan,IP19t_nan],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#頻遇 tarin 17、18 test 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X1, y1, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.975696\tvalid-auc:0.897335\n",
      "[1]\ttrain-auc:0.995158\tvalid-auc:0.844447\n",
      "[2]\ttrain-auc:0.999009\tvalid-auc:0.85754\n",
      "[3]\ttrain-auc:0.999935\tvalid-auc:0.875977\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.890334\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.909463\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.915768\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.920538\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.92813\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.931829\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12497 fp:   257\n",
      "fn:   352 tp:   161\n",
      "\n",
      "*** better f-score 0.3458646616541353\n",
      "max_depth :  30  colsample_bytree :  0.7  eta :  0.6  \n",
      "\n",
      "[0]\ttrain-auc:0.976481\tvalid-auc:0.883218\n",
      "[1]\ttrain-auc:0.994547\tvalid-auc:0.849669\n",
      "[2]\ttrain-auc:0.998608\tvalid-auc:0.877177\n",
      "[3]\ttrain-auc:0.999914\tvalid-auc:0.891642\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.901791\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.908567\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.913661\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.921426\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.926574\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.931363\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12507 fp:   247\n",
      "fn:   367 tp:   146\n",
      "\n",
      "[0]\ttrain-auc:0.97755\tvalid-auc:0.90245\n",
      "[1]\ttrain-auc:0.993816\tvalid-auc:0.843666\n",
      "[2]\ttrain-auc:0.998208\tvalid-auc:0.8695\n",
      "[3]\ttrain-auc:0.999835\tvalid-auc:0.892964\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.904226\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.906997\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.913839\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.920171\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.925766\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.931653\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12485 fp:   269\n",
      "fn:   350 tp:   163\n",
      "\n",
      "[0]\ttrain-auc:0.977704\tvalid-auc:0.880881\n",
      "[1]\ttrain-auc:0.995836\tvalid-auc:0.860266\n",
      "[2]\ttrain-auc:0.998772\tvalid-auc:0.886199\n",
      "[3]\ttrain-auc:0.99959\tvalid-auc:0.902716\n",
      "[4]\ttrain-auc:0.999963\tvalid-auc:0.899285\n",
      "[5]\ttrain-auc:0.999987\tvalid-auc:0.905329\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.910235\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.916338\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.921564\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.927714\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12480 fp:   274\n",
      "fn:   351 tp:   162\n",
      "\n",
      "[0]\ttrain-auc:0.970996\tvalid-auc:0.881169\n",
      "[1]\ttrain-auc:0.992467\tvalid-auc:0.835817\n",
      "[2]\ttrain-auc:0.99714\tvalid-auc:0.877719\n",
      "[3]\ttrain-auc:0.998958\tvalid-auc:0.901776\n",
      "[4]\ttrain-auc:0.999894\tvalid-auc:0.911117\n",
      "[5]\ttrain-auc:0.999994\tvalid-auc:0.919689\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.925496\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.929723\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.93281\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.934457\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12448 fp:   306\n",
      "fn:   339 tp:   174\n",
      "\n",
      "*** better f-score 0.3504531722054381\n",
      "max_depth :  20  colsample_bytree :  0.6  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.970996\tvalid-auc:0.881169\n",
      "[1]\ttrain-auc:0.992553\tvalid-auc:0.866748\n",
      "[2]\ttrain-auc:0.996433\tvalid-auc:0.885374\n",
      "[3]\ttrain-auc:0.998529\tvalid-auc:0.896947\n",
      "[4]\ttrain-auc:0.99945\tvalid-auc:0.907472\n",
      "[5]\ttrain-auc:0.999809\tvalid-auc:0.919822\n",
      "[6]\ttrain-auc:0.999939\tvalid-auc:0.928056\n",
      "[7]\ttrain-auc:0.999983\tvalid-auc:0.932064\n",
      "[8]\ttrain-auc:0.999983\tvalid-auc:0.933677\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.935614\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12403 fp:   351\n",
      "fn:   317 tp:   196\n",
      "\n",
      "*** better f-score 0.369811320754717\n",
      "max_depth :  20  colsample_bytree :  0.6  eta :  0.3  \n",
      "\n",
      "[0]\ttrain-auc:0.972176\tvalid-auc:0.897905\n",
      "[1]\ttrain-auc:0.991203\tvalid-auc:0.847218\n",
      "[2]\ttrain-auc:0.997976\tvalid-auc:0.865532\n",
      "[3]\ttrain-auc:0.999629\tvalid-auc:0.89879\n",
      "[4]\ttrain-auc:0.99994\tvalid-auc:0.903876\n",
      "[5]\ttrain-auc:0.999991\tvalid-auc:0.913215\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.914023\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.914357\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.92187\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.928168\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12459 fp:   295\n",
      "fn:   330 tp:   183\n",
      "\n",
      "[0]\ttrain-auc:0.969451\tvalid-auc:0.897189\n",
      "[1]\ttrain-auc:0.990051\tvalid-auc:0.862859\n",
      "[2]\ttrain-auc:0.995808\tvalid-auc:0.891056\n",
      "[3]\ttrain-auc:0.999011\tvalid-auc:0.901453\n",
      "[4]\ttrain-auc:0.999764\tvalid-auc:0.912192\n",
      "[5]\ttrain-auc:0.99997\tvalid-auc:0.911985\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.917743\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.922504\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.927756\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.930316\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12469 fp:   285\n",
      "fn:   345 tp:   168\n",
      "\n",
      "[0]\ttrain-auc:0.972176\tvalid-auc:0.897905\n",
      "[1]\ttrain-auc:0.991032\tvalid-auc:0.856555\n",
      "[2]\ttrain-auc:0.996798\tvalid-auc:0.869863\n",
      "[3]\ttrain-auc:0.999401\tvalid-auc:0.888977\n",
      "[4]\ttrain-auc:0.999906\tvalid-auc:0.903447\n",
      "[5]\ttrain-auc:0.99998\tvalid-auc:0.911677\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.916754\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.92364\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.928221\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.932738\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12475 fp:   279\n",
      "fn:   341 tp:   172\n",
      "\n",
      "[0]\ttrain-auc:0.976481\tvalid-auc:0.883218\n",
      "[1]\ttrain-auc:0.994526\tvalid-auc:0.855822\n",
      "[2]\ttrain-auc:0.998621\tvalid-auc:0.873706\n",
      "[3]\ttrain-auc:0.99965\tvalid-auc:0.886193\n",
      "[4]\ttrain-auc:0.999931\tvalid-auc:0.893739\n",
      "[5]\ttrain-auc:0.999995\tvalid-auc:0.906723\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.912294\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.920676\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.926849\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.92862\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12482 fp:   272\n",
      "fn:   354 tp:   159\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(pd.concat([X_9,X_t9],axis=0), label=pd.concat([y_9,y_t9],axis=0))\n",
    "y=pd.concat([y_9,y_t9],axis=0)\n",
    "#all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 22940 fp:     0\n",
      "fn:    51 tp:     0\n",
      "0.9977817406811361\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    " \n",
    "try:\n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "except:\n",
    "    precision =0\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "try:\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "except:\n",
    "    f_score=0\n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "#print(true_pos)\n",
    "#print(false_pos)\n",
    "print((true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#頻遇 tarin 17、19 test 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X2, y2, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.968893\tvalid-auc:0.89923\n",
      "[1]\ttrain-auc:0.990232\tvalid-auc:0.844259\n",
      "[2]\ttrain-auc:0.997228\tvalid-auc:0.872454\n",
      "[3]\ttrain-auc:0.999358\tvalid-auc:0.887119\n",
      "[4]\ttrain-auc:0.999919\tvalid-auc:0.898834\n",
      "[5]\ttrain-auc:0.999981\tvalid-auc:0.903993\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.907567\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.913676\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.922972\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.925803\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13289 fp:   277\n",
      "fn:   362 tp:   158\n",
      "\n",
      "*** better f-score 0.330890052356021\n",
      "max_depth :  20  colsample_bytree :  0.8  eta :  0.6  \n",
      "\n",
      "[0]\ttrain-auc:0.972141\tvalid-auc:0.874772\n",
      "[1]\ttrain-auc:0.991952\tvalid-auc:0.839112\n",
      "[2]\ttrain-auc:0.996593\tvalid-auc:0.869912\n",
      "[3]\ttrain-auc:0.999194\tvalid-auc:0.896463\n",
      "[4]\ttrain-auc:0.999778\tvalid-auc:0.907283\n",
      "[5]\ttrain-auc:0.999979\tvalid-auc:0.915314\n",
      "[6]\ttrain-auc:0.999994\tvalid-auc:0.914726\n",
      "[7]\ttrain-auc:0.999994\tvalid-auc:0.920427\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.923023\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.926802\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13229 fp:   337\n",
      "fn:   345 tp:   175\n",
      "\n",
      "*** better f-score 0.3391472868217054\n",
      "max_depth :  20  colsample_bytree :  0.5  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.976621\tvalid-auc:0.874385\n",
      "[1]\ttrain-auc:0.99442\tvalid-auc:0.822491\n",
      "[2]\ttrain-auc:0.998482\tvalid-auc:0.852752\n",
      "[3]\ttrain-auc:0.999784\tvalid-auc:0.86736\n",
      "[4]\ttrain-auc:0.999997\tvalid-auc:0.885344\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.895937\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.903468\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.912004\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.919873\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.922964\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13310 fp:   256\n",
      "fn:   389 tp:   131\n",
      "\n",
      "[0]\ttrain-auc:0.968893\tvalid-auc:0.89923\n",
      "[1]\ttrain-auc:0.989231\tvalid-auc:0.838898\n",
      "[2]\ttrain-auc:0.99663\tvalid-auc:0.853838\n",
      "[3]\ttrain-auc:0.999017\tvalid-auc:0.896532\n",
      "[4]\ttrain-auc:0.999674\tvalid-auc:0.908393\n",
      "[5]\ttrain-auc:0.99994\tvalid-auc:0.917813\n",
      "[6]\ttrain-auc:0.999977\tvalid-auc:0.922474\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.923415\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.924994\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.928836\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13223 fp:   343\n",
      "fn:   337 tp:   183\n",
      "\n",
      "*** better f-score 0.34990439770554493\n",
      "max_depth :  20  colsample_bytree :  0.8  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.975936\tvalid-auc:0.891159\n",
      "[1]\ttrain-auc:0.994105\tvalid-auc:0.845566\n",
      "[2]\ttrain-auc:0.997891\tvalid-auc:0.878437\n",
      "[3]\ttrain-auc:0.999677\tvalid-auc:0.889693\n",
      "[4]\ttrain-auc:0.999922\tvalid-auc:0.904657\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.908775\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.910834\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.916753\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.924314\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.933598\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13272 fp:   294\n",
      "fn:   385 tp:   135\n",
      "\n",
      "[0]\ttrain-auc:0.977074\tvalid-auc:0.901156\n",
      "[1]\ttrain-auc:0.993287\tvalid-auc:0.834397\n",
      "[2]\ttrain-auc:0.99828\tvalid-auc:0.852442\n",
      "[3]\ttrain-auc:0.999614\tvalid-auc:0.858315\n",
      "[4]\ttrain-auc:0.999905\tvalid-auc:0.876562\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.89597\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.900453\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.910935\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.92025\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.92464\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13275 fp:   291\n",
      "fn:   366 tp:   154\n",
      "\n",
      "[0]\ttrain-auc:0.972704\tvalid-auc:0.903128\n",
      "[1]\ttrain-auc:0.988038\tvalid-auc:0.864517\n",
      "[2]\ttrain-auc:0.994667\tvalid-auc:0.883929\n",
      "[3]\ttrain-auc:0.997293\tvalid-auc:0.904042\n",
      "[4]\ttrain-auc:0.999182\tvalid-auc:0.90663\n",
      "[5]\ttrain-auc:0.999792\tvalid-auc:0.9158\n",
      "[6]\ttrain-auc:0.999961\tvalid-auc:0.921059\n",
      "[7]\ttrain-auc:0.999989\tvalid-auc:0.925898\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.924978\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.92592\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13154 fp:   412\n",
      "fn:   320 tp:   200\n",
      "\n",
      "*** better f-score 0.3533568904593639\n",
      "max_depth :  20  colsample_bytree :  1.0  eta :  0.3  \n",
      "\n",
      "[0]\ttrain-auc:0.971674\tvalid-auc:0.902296\n",
      "[1]\ttrain-auc:0.99012\tvalid-auc:0.838923\n",
      "[2]\ttrain-auc:0.997805\tvalid-auc:0.857327\n",
      "[3]\ttrain-auc:0.999408\tvalid-auc:0.87568\n",
      "[4]\ttrain-auc:0.999954\tvalid-auc:0.883355\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.893945\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.901211\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.905752\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.912121\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.918115\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13270 fp:   296\n",
      "fn:   359 tp:   161\n",
      "\n",
      "[0]\ttrain-auc:0.975499\tvalid-auc:0.903167\n",
      "[1]\ttrain-auc:0.992893\tvalid-auc:0.833011\n",
      "[2]\ttrain-auc:0.998405\tvalid-auc:0.848279\n",
      "[3]\ttrain-auc:0.999811\tvalid-auc:0.873573\n",
      "[4]\ttrain-auc:0.999986\tvalid-auc:0.887498\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.90249\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.911396\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.920559\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.926661\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.930439\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13296 fp:   270\n",
      "fn:   387 tp:   133\n",
      "\n",
      "[0]\ttrain-auc:0.97616\tvalid-auc:0.897889\n",
      "[1]\ttrain-auc:0.993736\tvalid-auc:0.839066\n",
      "[2]\ttrain-auc:0.998039\tvalid-auc:0.872105\n",
      "[3]\ttrain-auc:0.999669\tvalid-auc:0.887538\n",
      "[4]\ttrain-auc:0.999972\tvalid-auc:0.898841\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.905085\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.912034\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.920279\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.925484\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.928971\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13275 fp:   291\n",
      "fn:   370 tp:   150\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(pd.concat([X_8,X_t8],axis=0), label=pd.concat([y_8,y_t8],axis=0))\n",
    "y=pd.concat([y_8,y_t8],axis=0)\n",
    "#all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 20471 fp:     0\n",
      "fn:    39 tp:     0\n",
      "0.9980984885421745\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "try:  \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "except:\n",
    "    precision =0\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "try:\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "except:\n",
    "    f_score=0\n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "#print(true_pos)\n",
    "#print(false_pos)\n",
    "print((true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#頻遇 tarin 19、18 test 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X3, y3, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.999379\tvalid-auc:0.951263\n",
      "[1]\ttrain-auc:0.999929\tvalid-auc:0.942639\n",
      "[2]\ttrain-auc:0.999982\tvalid-auc:0.87939\n",
      "[3]\ttrain-auc:1\tvalid-auc:0.953174\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.957324\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.988323\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.990949\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.991511\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.991102\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.989244\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14314 fp:    13\n",
      "fn:    16 tp:    13\n",
      "\n",
      "*** better f-score 0.4727272727272727\n",
      "max_depth :  30  colsample_bytree :  0.5  eta :  0.5  \n",
      "\n",
      "[0]\ttrain-auc:0.999432\tvalid-auc:0.962648\n",
      "[1]\ttrain-auc:0.999769\tvalid-auc:0.963334\n",
      "[2]\ttrain-auc:0.999893\tvalid-auc:0.962524\n",
      "[3]\ttrain-auc:0.999946\tvalid-auc:0.935198\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.978278\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.979171\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.92061\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.977756\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.952222\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.9543\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14309 fp:    18\n",
      "fn:    17 tp:    12\n",
      "\n",
      "[0]\ttrain-auc:0.99968\tvalid-auc:0.962721\n",
      "[1]\ttrain-auc:0.999805\tvalid-auc:0.962921\n",
      "[2]\ttrain-auc:0.999858\tvalid-auc:0.962191\n",
      "[3]\ttrain-auc:0.999928\tvalid-auc:0.96364\n",
      "[4]\ttrain-auc:0.999964\tvalid-auc:0.964681\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.97743\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.987243\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.988515\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.988767\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.99082\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14306 fp:    21\n",
      "fn:    17 tp:    12\n",
      "\n",
      "[0]\ttrain-auc:0.999379\tvalid-auc:0.951263\n",
      "[1]\ttrain-auc:0.999929\tvalid-auc:0.877328\n",
      "[2]\ttrain-auc:0.999982\tvalid-auc:0.813043\n",
      "[3]\ttrain-auc:1\tvalid-auc:0.857022\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.923655\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.954969\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.991313\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.991211\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.98922\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.992676\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14312 fp:    15\n",
      "fn:    17 tp:    12\n",
      "\n",
      "[0]\ttrain-auc:0.999521\tvalid-auc:0.963836\n",
      "[1]\ttrain-auc:0.999947\tvalid-auc:0.941271\n",
      "[2]\ttrain-auc:0.999982\tvalid-auc:0.878072\n",
      "[3]\ttrain-auc:0.999982\tvalid-auc:0.956681\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.955276\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.98418\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.988315\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.987953\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.987318\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.99005\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14308 fp:    19\n",
      "fn:    16 tp:    13\n",
      "\n",
      "[0]\ttrain-auc:0.999663\tvalid-auc:0.963793\n",
      "[1]\ttrain-auc:0.999964\tvalid-auc:0.976006\n",
      "[2]\ttrain-auc:0.999982\tvalid-auc:0.975622\n",
      "[3]\ttrain-auc:0.999982\tvalid-auc:0.955992\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.985208\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.986523\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.989263\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.988594\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.986604\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.988949\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14311 fp:    16\n",
      "fn:    17 tp:    12\n",
      "\n",
      "[0]\ttrain-auc:0.99968\tvalid-auc:0.962721\n",
      "[1]\ttrain-auc:0.999822\tvalid-auc:0.962953\n",
      "[2]\ttrain-auc:0.999893\tvalid-auc:0.963066\n",
      "[3]\ttrain-auc:0.999947\tvalid-auc:0.963873\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.976816\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.976733\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.97823\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.978505\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.979736\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.990712\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14306 fp:    21\n",
      "fn:    17 tp:    12\n",
      "\n",
      "[0]\ttrain-auc:0.999609\tvalid-auc:0.963769\n",
      "[1]\ttrain-auc:0.999876\tvalid-auc:0.96431\n",
      "[2]\ttrain-auc:0.999947\tvalid-auc:0.964236\n",
      "[3]\ttrain-auc:0.999947\tvalid-auc:0.964006\n",
      "[4]\ttrain-auc:0.999982\tvalid-auc:0.97682\n",
      "[5]\ttrain-auc:0.999982\tvalid-auc:0.976436\n",
      "[6]\ttrain-auc:0.999982\tvalid-auc:0.976508\n",
      "[7]\ttrain-auc:0.999982\tvalid-auc:0.989616\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.99127\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.99042\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14305 fp:    22\n",
      "fn:    17 tp:    12\n",
      "\n",
      "[0]\ttrain-auc:0.99968\tvalid-auc:0.962721\n",
      "[1]\ttrain-auc:0.99984\tvalid-auc:0.961811\n",
      "[2]\ttrain-auc:0.999964\tvalid-auc:0.96269\n",
      "[3]\ttrain-auc:1\tvalid-auc:0.96658\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.967584\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.978987\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.988172\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.988362\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.987856\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.987173\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14312 fp:    15\n",
      "fn:    17 tp:    12\n",
      "\n",
      "[0]\ttrain-auc:0.99837\tvalid-auc:0.950932\n",
      "[1]\ttrain-auc:0.999734\tvalid-auc:0.775231\n",
      "[2]\ttrain-auc:0.999949\tvalid-auc:0.777776\n",
      "[3]\ttrain-auc:0.999983\tvalid-auc:0.855373\n",
      "[4]\ttrain-auc:0.999983\tvalid-auc:0.889317\n",
      "[5]\ttrain-auc:0.999983\tvalid-auc:0.891488\n",
      "[6]\ttrain-auc:0.999984\tvalid-auc:0.925493\n",
      "[7]\ttrain-auc:0.999983\tvalid-auc:0.92602\n",
      "[8]\ttrain-auc:0.999983\tvalid-auc:0.958525\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.957821\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14307 fp:    20\n",
      "fn:    16 tp:    13\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(pd.concat([X_7,X_t7],axis=0), label=pd.concat([y_7,y_t7],axis=0))\n",
    "y=pd.concat([y_7,y_t7],axis=0)\n",
    "#all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 18086 fp:     1\n",
      "fn:  1606 tp:     0\n",
      "0.918397400091403\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "   \n",
    "try:  \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "except:\n",
    "    precision =0\n",
    "    \n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "try:\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "except:\n",
    "    f_score=0\n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "#print(true_pos)\n",
    "#print(false_pos)\n",
    "print((true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#時域 tarin 17、18 test 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X4, y4, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.946593\tvalid-auc:0.875713\n",
      "[1]\ttrain-auc:0.980794\tvalid-auc:0.830479\n",
      "[2]\ttrain-auc:0.991964\tvalid-auc:0.841656\n",
      "[3]\ttrain-auc:0.996723\tvalid-auc:0.8397\n",
      "[4]\ttrain-auc:0.999582\tvalid-auc:0.844793\n",
      "[5]\ttrain-auc:0.999891\tvalid-auc:0.854856\n",
      "[6]\ttrain-auc:0.999991\tvalid-auc:0.864021\n",
      "[7]\ttrain-auc:0.999998\tvalid-auc:0.871386\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.874824\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.878521\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12382 fp:   372\n",
      "fn:   393 tp:   120\n",
      "\n",
      "*** better f-score 0.23880597014925373\n",
      "max_depth :  20  colsample_bytree :  0.8  eta :  0.6  \n",
      "\n",
      "[0]\ttrain-auc:0.946593\tvalid-auc:0.875713\n",
      "[1]\ttrain-auc:0.974308\tvalid-auc:0.858317\n",
      "[2]\ttrain-auc:0.98823\tvalid-auc:0.861388\n",
      "[3]\ttrain-auc:0.993532\tvalid-auc:0.867481\n",
      "[4]\ttrain-auc:0.996497\tvalid-auc:0.878056\n",
      "[5]\ttrain-auc:0.998708\tvalid-auc:0.881308\n",
      "[6]\ttrain-auc:0.999513\tvalid-auc:0.891072\n",
      "[7]\ttrain-auc:0.999802\tvalid-auc:0.892622\n",
      "[8]\ttrain-auc:0.999878\tvalid-auc:0.891444\n",
      "[9]\ttrain-auc:0.999983\tvalid-auc:0.890363\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12055 fp:   699\n",
      "fn:   335 tp:   178\n",
      "\n",
      "*** better f-score 0.2561151079136691\n",
      "max_depth :  20  colsample_bytree :  0.8  eta :  0.3  \n",
      "\n",
      "[0]\ttrain-auc:0.961638\tvalid-auc:0.877347\n",
      "[1]\ttrain-auc:0.984845\tvalid-auc:0.859159\n",
      "[2]\ttrain-auc:0.994836\tvalid-auc:0.829876\n",
      "[3]\ttrain-auc:0.998606\tvalid-auc:0.840722\n",
      "[4]\ttrain-auc:0.999462\tvalid-auc:0.851446\n",
      "[5]\ttrain-auc:0.999857\tvalid-auc:0.861121\n",
      "[6]\ttrain-auc:0.999982\tvalid-auc:0.870576\n",
      "[7]\ttrain-auc:0.999991\tvalid-auc:0.87507\n",
      "[8]\ttrain-auc:0.999997\tvalid-auc:0.880645\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.878054\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12299 fp:   455\n",
      "fn:   380 tp:   133\n",
      "\n",
      "[0]\ttrain-auc:0.955855\tvalid-auc:0.8736\n",
      "[1]\ttrain-auc:0.984039\tvalid-auc:0.849884\n",
      "[2]\ttrain-auc:0.99297\tvalid-auc:0.852614\n",
      "[3]\ttrain-auc:0.996473\tvalid-auc:0.865165\n",
      "[4]\ttrain-auc:0.998301\tvalid-auc:0.871223\n",
      "[5]\ttrain-auc:0.999257\tvalid-auc:0.875673\n",
      "[6]\ttrain-auc:0.999461\tvalid-auc:0.878692\n",
      "[7]\ttrain-auc:0.999837\tvalid-auc:0.882355\n",
      "[8]\ttrain-auc:0.99997\tvalid-auc:0.883624\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.885685\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12107 fp:   647\n",
      "fn:   345 tp:   168\n",
      "\n",
      "[0]\ttrain-auc:0.979464\tvalid-auc:0.87182\n",
      "[1]\ttrain-auc:0.994363\tvalid-auc:0.819698\n",
      "[2]\ttrain-auc:0.999679\tvalid-auc:0.833417\n",
      "[3]\ttrain-auc:0.999997\tvalid-auc:0.832559\n",
      "[4]\ttrain-auc:0.999999\tvalid-auc:0.850687\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.862837\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.872349\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.882854\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.886714\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.889279\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12498 fp:   256\n",
      "fn:   418 tp:    95\n",
      "\n",
      "[0]\ttrain-auc:0.979464\tvalid-auc:0.87182\n",
      "[1]\ttrain-auc:0.993304\tvalid-auc:0.860891\n",
      "[2]\ttrain-auc:0.998864\tvalid-auc:0.847058\n",
      "[3]\ttrain-auc:0.999864\tvalid-auc:0.841628\n",
      "[4]\ttrain-auc:0.999996\tvalid-auc:0.838519\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.847213\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.860002\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.869426\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.876642\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.881914\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12481 fp:   273\n",
      "fn:   426 tp:    87\n",
      "\n",
      "[0]\ttrain-auc:0.946593\tvalid-auc:0.875713\n",
      "[1]\ttrain-auc:0.976467\tvalid-auc:0.850147\n",
      "[2]\ttrain-auc:0.990493\tvalid-auc:0.850089\n",
      "[3]\ttrain-auc:0.995712\tvalid-auc:0.865721\n",
      "[4]\ttrain-auc:0.998705\tvalid-auc:0.868689\n",
      "[5]\ttrain-auc:0.999589\tvalid-auc:0.866853\n",
      "[6]\ttrain-auc:0.999941\tvalid-auc:0.871318\n",
      "[7]\ttrain-auc:0.999996\tvalid-auc:0.877367\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.88352\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.884135\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12326 fp:   428\n",
      "fn:   373 tp:   140\n",
      "\n",
      "*** better f-score 0.2590194264569843\n",
      "max_depth :  20  colsample_bytree :  0.8  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.973543\tvalid-auc:0.879018\n",
      "[1]\ttrain-auc:0.994038\tvalid-auc:0.80318\n",
      "[2]\ttrain-auc:0.999299\tvalid-auc:0.783853\n",
      "[3]\ttrain-auc:0.999971\tvalid-auc:0.797775\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.825497\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.855443\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.869369\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.877197\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.882349\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.887336\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12454 fp:   300\n",
      "fn:   414 tp:    99\n",
      "\n",
      "[0]\ttrain-auc:0.96979\tvalid-auc:0.87284\n",
      "[1]\ttrain-auc:0.990157\tvalid-auc:0.827815\n",
      "[2]\ttrain-auc:0.996549\tvalid-auc:0.842141\n",
      "[3]\ttrain-auc:0.999319\tvalid-auc:0.843685\n",
      "[4]\ttrain-auc:0.999882\tvalid-auc:0.854752\n",
      "[5]\ttrain-auc:0.999982\tvalid-auc:0.859663\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.868005\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.876915\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.879725\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.88359\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12397 fp:   357\n",
      "fn:   392 tp:   121\n",
      "\n",
      "[0]\ttrain-auc:0.946793\tvalid-auc:0.874181\n",
      "[1]\ttrain-auc:0.980729\tvalid-auc:0.829337\n",
      "[2]\ttrain-auc:0.990308\tvalid-auc:0.840482\n",
      "[3]\ttrain-auc:0.99646\tvalid-auc:0.845858\n",
      "[4]\ttrain-auc:0.999546\tvalid-auc:0.848887\n",
      "[5]\ttrain-auc:0.999942\tvalid-auc:0.858626\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.867318\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.877777\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.879142\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.881659\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 12367 fp:   387\n",
      "fn:   392 tp:   121\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(pd.concat([IP19_nan,IP19t_nan],axis=0), label=pd.concat([y_9,y_t9],axis=0))\n",
    "y=pd.concat([y_9,y_t9],axis=0)\n",
    "#all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 22779 fp:   161\n",
      "fn:    51 tp:     0\n",
      "0.9907790004784481\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "try:\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "except:\n",
    "    f_score=0\n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "#print(true_pos)\n",
    "#print(false_pos)\n",
    "print((true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#時域 tarin 17、19 test 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X5, y5, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.961552\tvalid-auc:0.877555\n",
      "[1]\ttrain-auc:0.981924\tvalid-auc:0.854577\n",
      "[2]\ttrain-auc:0.991138\tvalid-auc:0.864027\n",
      "[3]\ttrain-auc:0.996877\tvalid-auc:0.864873\n",
      "[4]\ttrain-auc:0.999058\tvalid-auc:0.864087\n",
      "[5]\ttrain-auc:0.999771\tvalid-auc:0.874744\n",
      "[6]\ttrain-auc:0.999989\tvalid-auc:0.878108\n",
      "[7]\ttrain-auc:0.999999\tvalid-auc:0.881775\n",
      "[8]\ttrain-auc:0.999999\tvalid-auc:0.884793\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.886284\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13140 fp:   426\n",
      "fn:   397 tp:   123\n",
      "\n",
      "*** better f-score 0.23012160898035547\n",
      "max_depth :  20  colsample_bytree :  0.5  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.969416\tvalid-auc:0.877141\n",
      "[1]\ttrain-auc:0.989514\tvalid-auc:0.820458\n",
      "[2]\ttrain-auc:0.995372\tvalid-auc:0.838512\n",
      "[3]\ttrain-auc:0.998881\tvalid-auc:0.845251\n",
      "[4]\ttrain-auc:0.999819\tvalid-auc:0.853707\n",
      "[5]\ttrain-auc:0.999925\tvalid-auc:0.8602\n",
      "[6]\ttrain-auc:0.999997\tvalid-auc:0.87177\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.88036\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.883936\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.89166\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13228 fp:   338\n",
      "fn:   408 tp:   112\n",
      "\n",
      "*** better f-score 0.23092783505154638\n",
      "max_depth :  25  colsample_bytree :  0.8  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.979837\tvalid-auc:0.875549\n",
      "[1]\ttrain-auc:0.995303\tvalid-auc:0.858187\n",
      "[2]\ttrain-auc:0.999126\tvalid-auc:0.858792\n",
      "[3]\ttrain-auc:0.999791\tvalid-auc:0.862458\n",
      "[4]\ttrain-auc:0.999966\tvalid-auc:0.869983\n",
      "[5]\ttrain-auc:0.999997\tvalid-auc:0.87186\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.881937\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.884071\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.888928\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.890674\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13287 fp:   279\n",
      "fn:   439 tp:    81\n",
      "\n",
      "[0]\ttrain-auc:0.981495\tvalid-auc:0.879967\n",
      "[1]\ttrain-auc:0.995543\tvalid-auc:0.828117\n",
      "[2]\ttrain-auc:0.999165\tvalid-auc:0.804972\n",
      "[3]\ttrain-auc:0.999931\tvalid-auc:0.815075\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.831194\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.840865\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.857779\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.862679\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.876311\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.883666\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13327 fp:   239\n",
      "fn:   420 tp:   100\n",
      "\n",
      "*** better f-score 0.23282887077997672\n",
      "max_depth :  30  colsample_bytree :  0.7  eta :  0.5  \n",
      "\n",
      "[0]\ttrain-auc:0.953509\tvalid-auc:0.876951\n",
      "[1]\ttrain-auc:0.984682\tvalid-auc:0.823211\n",
      "[2]\ttrain-auc:0.993112\tvalid-auc:0.839465\n",
      "[3]\ttrain-auc:0.999167\tvalid-auc:0.840925\n",
      "[4]\ttrain-auc:0.999833\tvalid-auc:0.849654\n",
      "[5]\ttrain-auc:0.999996\tvalid-auc:0.853643\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.860966\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.8689\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.869293\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.87733\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13229 fp:   337\n",
      "fn:   434 tp:    86\n",
      "\n",
      "[0]\ttrain-auc:0.977301\tvalid-auc:0.878419\n",
      "[1]\ttrain-auc:0.991338\tvalid-auc:0.840885\n",
      "[2]\ttrain-auc:0.997869\tvalid-auc:0.828931\n",
      "[3]\ttrain-auc:0.999838\tvalid-auc:0.838851\n",
      "[4]\ttrain-auc:0.999952\tvalid-auc:0.847748\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.857842\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.872755\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.880988\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.886225\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.89374\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13283 fp:   283\n",
      "fn:   419 tp:   101\n",
      "\n",
      "[0]\ttrain-auc:0.963368\tvalid-auc:0.880391\n",
      "[1]\ttrain-auc:0.980904\tvalid-auc:0.853578\n",
      "[2]\ttrain-auc:0.991575\tvalid-auc:0.84589\n",
      "[3]\ttrain-auc:0.997571\tvalid-auc:0.851194\n",
      "[4]\ttrain-auc:0.99891\tvalid-auc:0.857522\n",
      "[5]\ttrain-auc:0.999795\tvalid-auc:0.866429\n",
      "[6]\ttrain-auc:0.999972\tvalid-auc:0.867968\n",
      "[7]\ttrain-auc:0.999989\tvalid-auc:0.87484\n",
      "[8]\ttrain-auc:0.999999\tvalid-auc:0.879379\n",
      "[9]\ttrain-auc:0.999995\tvalid-auc:0.885132\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13166 fp:   400\n",
      "fn:   394 tp:   126\n",
      "\n",
      "*** better f-score 0.24091778202676867\n",
      "max_depth :  20  colsample_bytree :  0.6  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.953928\tvalid-auc:0.877383\n",
      "[1]\ttrain-auc:0.974823\tvalid-auc:0.828305\n",
      "[2]\ttrain-auc:0.988156\tvalid-auc:0.845068\n",
      "[3]\ttrain-auc:0.995156\tvalid-auc:0.84677\n",
      "[4]\ttrain-auc:0.998396\tvalid-auc:0.858804\n",
      "[5]\ttrain-auc:0.999659\tvalid-auc:0.854665\n",
      "[6]\ttrain-auc:0.999856\tvalid-auc:0.86398\n",
      "[7]\ttrain-auc:0.999968\tvalid-auc:0.870882\n",
      "[8]\ttrain-auc:0.999999\tvalid-auc:0.878502\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.883601\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13108 fp:   458\n",
      "fn:   381 tp:   139\n",
      "\n",
      "*** better f-score 0.24888093106535364\n",
      "max_depth :  20  colsample_bytree :  0.9  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.962041\tvalid-auc:0.881799\n",
      "[1]\ttrain-auc:0.982101\tvalid-auc:0.846134\n",
      "[2]\ttrain-auc:0.992158\tvalid-auc:0.848529\n",
      "[3]\ttrain-auc:0.998071\tvalid-auc:0.842812\n",
      "[4]\ttrain-auc:0.999488\tvalid-auc:0.857133\n",
      "[5]\ttrain-auc:0.999938\tvalid-auc:0.860413\n",
      "[6]\ttrain-auc:0.999999\tvalid-auc:0.869461\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.871635\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.877767\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.878583\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13214 fp:   352\n",
      "fn:   408 tp:   112\n",
      "\n",
      "[0]\ttrain-auc:0.979837\tvalid-auc:0.875549\n",
      "[1]\ttrain-auc:0.995529\tvalid-auc:0.840097\n",
      "[2]\ttrain-auc:0.999173\tvalid-auc:0.838689\n",
      "[3]\ttrain-auc:0.99991\tvalid-auc:0.835163\n",
      "[4]\ttrain-auc:0.99999\tvalid-auc:0.850617\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.857111\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.86716\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.877772\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.886931\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.890909\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 13330 fp:   236\n",
      "fn:   429 tp:    91\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(pd.concat([IP18_nan,IP18t_nan],axis=0), label=pd.concat([y_8,y_t8],axis=0))\n",
    "y=pd.concat([y_8,y_t8],axis=0)\n",
    "#all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 20467 fp:     4\n",
      "fn:    39 tp:     0\n",
      "0.9979034617259873\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "try:\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "except:\n",
    "    f_score=0\n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "#print(true_pos)\n",
    "#print(false_pos)\n",
    "print((true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#時域 tarin 19、18 test 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X6, y6, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.999263\tvalid-auc:0.992548\n",
      "[1]\ttrain-auc:0.999466\tvalid-auc:0.994517\n",
      "[2]\ttrain-auc:0.999483\tvalid-auc:0.994944\n",
      "[3]\ttrain-auc:0.999683\tvalid-auc:0.995315\n",
      "[4]\ttrain-auc:0.999827\tvalid-auc:0.995441\n",
      "[5]\ttrain-auc:0.999859\tvalid-auc:0.995478\n",
      "[6]\ttrain-auc:0.999956\tvalid-auc:0.961494\n",
      "[7]\ttrain-auc:0.999993\tvalid-auc:0.9956\n",
      "[8]\ttrain-auc:0.999999\tvalid-auc:0.995638\n",
      "[9]\ttrain-auc:0.999999\tvalid-auc:0.994843\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14309 fp:    18\n",
      "fn:    10 tp:    19\n",
      "\n",
      "*** better f-score 0.5757575757575758\n",
      "max_depth :  20  colsample_bytree :  1.0  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.999139\tvalid-auc:0.992878\n",
      "[1]\ttrain-auc:0.999414\tvalid-auc:0.99319\n",
      "[2]\ttrain-auc:0.999562\tvalid-auc:0.993284\n",
      "[3]\ttrain-auc:0.999763\tvalid-auc:0.995124\n",
      "[4]\ttrain-auc:0.999763\tvalid-auc:0.995162\n",
      "[5]\ttrain-auc:0.999844\tvalid-auc:0.994393\n",
      "[6]\ttrain-auc:0.999938\tvalid-auc:0.998162\n",
      "[7]\ttrain-auc:0.999951\tvalid-auc:0.998085\n",
      "[8]\ttrain-auc:0.999999\tvalid-auc:0.998439\n",
      "[9]\ttrain-auc:0.999998\tvalid-auc:0.998608\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14304 fp:    23\n",
      "fn:     9 tp:    20\n",
      "\n",
      "[0]\ttrain-auc:0.998866\tvalid-auc:0.997546\n",
      "[1]\ttrain-auc:0.999507\tvalid-auc:0.998199\n",
      "[2]\ttrain-auc:0.999733\tvalid-auc:0.998523\n",
      "[3]\ttrain-auc:0.999835\tvalid-auc:0.99833\n",
      "[4]\ttrain-auc:0.999957\tvalid-auc:0.998564\n",
      "[5]\ttrain-auc:0.999949\tvalid-auc:0.998794\n",
      "[6]\ttrain-auc:0.999948\tvalid-auc:0.999063\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999167\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999223\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999146\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14312 fp:    15\n",
      "fn:     6 tp:    23\n",
      "\n",
      "*** better f-score 0.6865671641791046\n",
      "max_depth :  20  colsample_bytree :  0.5  eta :  0.6  \n",
      "\n",
      "[0]\ttrain-auc:0.999208\tvalid-auc:0.992978\n",
      "[1]\ttrain-auc:0.999414\tvalid-auc:0.993088\n",
      "[2]\ttrain-auc:0.999579\tvalid-auc:0.993317\n",
      "[3]\ttrain-auc:0.999763\tvalid-auc:0.995095\n",
      "[4]\ttrain-auc:0.999912\tvalid-auc:0.96108\n",
      "[5]\ttrain-auc:0.999913\tvalid-auc:0.961217\n",
      "[6]\ttrain-auc:0.999952\tvalid-auc:0.960678\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.960624\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.960624\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.961278\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14310 fp:    17\n",
      "fn:     9 tp:    20\n",
      "\n",
      "[0]\ttrain-auc:0.999338\tvalid-auc:0.997795\n",
      "[1]\ttrain-auc:0.999731\tvalid-auc:0.998136\n",
      "[2]\ttrain-auc:0.999825\tvalid-auc:0.998391\n",
      "[3]\ttrain-auc:0.999902\tvalid-auc:0.998204\n",
      "[4]\ttrain-auc:0.999958\tvalid-auc:0.998152\n",
      "[5]\ttrain-auc:0.999954\tvalid-auc:0.998267\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.998466\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999025\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999088\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.99902\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14320 fp:     7\n",
      "fn:     6 tp:    23\n",
      "\n",
      "*** better f-score 0.7796610169491527\n",
      "max_depth :  30  colsample_bytree :  0.5  eta :  0.6  \n",
      "\n",
      "[0]\ttrain-auc:0.999208\tvalid-auc:0.992978\n",
      "[1]\ttrain-auc:0.999414\tvalid-auc:0.99309\n",
      "[2]\ttrain-auc:0.999697\tvalid-auc:0.993232\n",
      "[3]\ttrain-auc:0.999733\tvalid-auc:0.994888\n",
      "[4]\ttrain-auc:0.999733\tvalid-auc:0.994872\n",
      "[5]\ttrain-auc:0.999795\tvalid-auc:0.994651\n",
      "[6]\ttrain-auc:0.999829\tvalid-auc:0.99551\n",
      "[7]\ttrain-auc:0.999914\tvalid-auc:0.995596\n",
      "[8]\ttrain-auc:0.999955\tvalid-auc:0.997965\n",
      "[9]\ttrain-auc:0.999999\tvalid-auc:0.998355\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14308 fp:    19\n",
      "fn:    10 tp:    19\n",
      "\n",
      "[0]\ttrain-auc:0.999277\tvalid-auc:0.992828\n",
      "[1]\ttrain-auc:0.999466\tvalid-auc:0.993808\n",
      "[2]\ttrain-auc:0.999466\tvalid-auc:0.993781\n",
      "[3]\ttrain-auc:0.999552\tvalid-auc:0.993825\n",
      "[4]\ttrain-auc:0.999579\tvalid-auc:0.993944\n",
      "[5]\ttrain-auc:0.999746\tvalid-auc:0.994035\n",
      "[6]\ttrain-auc:0.999846\tvalid-auc:0.994258\n",
      "[7]\ttrain-auc:0.999863\tvalid-auc:0.994272\n",
      "[8]\ttrain-auc:0.999863\tvalid-auc:0.994267\n",
      "[9]\ttrain-auc:0.999973\tvalid-auc:0.994084\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14308 fp:    19\n",
      "fn:    10 tp:    19\n",
      "\n",
      "[0]\ttrain-auc:0.999487\tvalid-auc:0.994172\n",
      "[1]\ttrain-auc:0.999821\tvalid-auc:0.99786\n",
      "[2]\ttrain-auc:0.999894\tvalid-auc:0.998237\n",
      "[3]\ttrain-auc:0.999898\tvalid-auc:0.998091\n",
      "[4]\ttrain-auc:0.999948\tvalid-auc:0.998081\n",
      "[5]\ttrain-auc:0.999945\tvalid-auc:0.998076\n",
      "[6]\ttrain-auc:0.999945\tvalid-auc:0.998272\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.998438\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.998099\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.998426\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14315 fp:    12\n",
      "fn:     8 tp:    21\n",
      "\n",
      "[0]\ttrain-auc:0.999139\tvalid-auc:0.992878\n",
      "[1]\ttrain-auc:0.999363\tvalid-auc:0.993073\n",
      "[2]\ttrain-auc:0.999562\tvalid-auc:0.993335\n",
      "[3]\ttrain-auc:0.99958\tvalid-auc:0.99494\n",
      "[4]\ttrain-auc:0.999763\tvalid-auc:0.995129\n",
      "[5]\ttrain-auc:0.999746\tvalid-auc:0.994277\n",
      "[6]\ttrain-auc:0.999747\tvalid-auc:0.963889\n",
      "[7]\ttrain-auc:0.999824\tvalid-auc:0.964012\n",
      "[8]\ttrain-auc:0.999959\tvalid-auc:0.99834\n",
      "[9]\ttrain-auc:0.999958\tvalid-auc:0.998309\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14303 fp:    24\n",
      "fn:    10 tp:    19\n",
      "\n",
      "[0]\ttrain-auc:0.999139\tvalid-auc:0.992878\n",
      "[1]\ttrain-auc:0.999414\tvalid-auc:0.993351\n",
      "[2]\ttrain-auc:0.999662\tvalid-auc:0.993528\n",
      "[3]\ttrain-auc:0.999765\tvalid-auc:0.961358\n",
      "[4]\ttrain-auc:0.999894\tvalid-auc:0.961624\n",
      "[5]\ttrain-auc:0.999999\tvalid-auc:0.962177\n",
      "[6]\ttrain-auc:0.999998\tvalid-auc:0.998634\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.998585\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.998371\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.99799\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 14311 fp:    16\n",
      "fn:     8 tp:    21\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(pd.concat([IP17_nan,IP17t_nan],axis=0), label=pd.concat([y_7,y_t7],axis=0))\n",
    "y=pd.concat([y_7,y_t7],axis=0)\n",
    "#all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 18085 fp:     2\n",
      "fn:  1606 tp:     0\n",
      "0.9183466206266186\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "try:\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "except:\n",
    "    f_score=0\n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "#print(true_pos)\n",
    "#print(false_pos)\n",
    "print((true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
