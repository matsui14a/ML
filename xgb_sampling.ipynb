{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # import numpy\n",
    "import pandas as pd # import pandas\n",
    "import zipfile # import 解zip壓縮檔\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "folders='/home/jovyan/at082-group10/nathan/For_AIA_0916_1018_Sample'\n",
    "all_data=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all csv data\n",
    "for folders in glob.glob('/home/jovyan/at082-group10/nathan/For_AIA_0916_1018_Sample/IP*/*'):\n",
    "    for file in glob.glob(folders+'/FeatureNEW/'):\n",
    "        \n",
    "        for filename in os.listdir(file):\n",
    "            if (os.path.splitext(filename)[-1]=='.csv'): # only read 副檔為csv\n",
    "                #print(os.path.join(file,filename))\n",
    "                #print(file.split('/')[7])\n",
    "                if(file.split('/')[6]=='IP17' or file.split('/')[6]=='IP18' or file.split('/')[6]=='IP19'):\n",
    "                    \n",
    "                    temp_pd=pd.read_csv(os.path.join(file,filename))\n",
    "                    temp_pd.insert(0,column=\"machiine\",value=file.split('/')[6]) # 新增機台欄位\n",
    "                    if(all_data is None):\n",
    "                        all_data=temp_pd\n",
    "                    else :\n",
    "                        all_data=pd.concat([all_data,temp_pd],axis=0, ignore_index=True)\n",
    "            else :\n",
    "                next\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_t=[]\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "for i in range(len(all_data)):\n",
    "    if (datetime.strptime((all_data['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-16 04:00',\"%Y-%m-%d %H:%M\")>timedelta(minutes=0)):\n",
    "        if(all_data['machiine'][i]=='IP17'):\n",
    "            la_t.append('1')\n",
    "        else:\n",
    "            la_t.append('0')\n",
    "    else:\n",
    "        la_t.append('0')\n",
    "        \n",
    "#all_data=pd.concat([all_data,la_t],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(la_t, columns = ['lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.concat([all_data,df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame()\n",
    "temp_pd2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all csv data\n",
    "for folders in glob.glob('/home/jovyan/at082-group10/For_AIA_1019_1029/IP*/*'):\n",
    "    #print(\"1\")\n",
    "    for file in glob.glob(folders+'/FeatureNEW/'):\n",
    "        #print('2')\n",
    "        for filename in os.listdir(file):\n",
    "            #print('3')\n",
    "            if (os.path.splitext(filename)[-1]=='.csv'): # only read 副檔為csv\n",
    "                #print('4')\n",
    "                #print(os.path.join(file,filename))\n",
    "                #print(file.split('/')[7])\n",
    "               \n",
    "                if(file.split('/')[5]=='IP17' or file.split('/')[5]=='IP18' or file.split('/')[5]=='IP19'):\n",
    "                    #print('5')\n",
    "                    temp_pd2=pd.read_csv(os.path.join(file,filename))\n",
    "                    temp_pd2.insert(0,column=\"machiine\",value=file.split('/')[5]) # 新增機台欄位\n",
    "                    \n",
    "                    if(test is None):\n",
    "                        test=temp_pd2\n",
    "                    else :\n",
    "                        test=pd.concat([test,temp_pd2],axis=0, ignore_index=True)\n",
    "            else :\n",
    "                next\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_t=[]\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "for i in range(len(test)):\n",
    "    if(test['machiine'][i]=='IP17'):\n",
    "        if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 15:00',\"%Y-%m-%d %H:%M\")>timedelta(minutes=0)):\n",
    "            if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 17:11',\"%Y-%m-%d %H:%M\")<timedelta(minutes=0)):\n",
    "                la_t.append('1')\n",
    "            else:\n",
    "                 la_t.append('0')\n",
    "        else:\n",
    "             la_t.append('0')\n",
    "    elif (test['machiine'][i]=='IP18'):\n",
    "        if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 11:00',\"%Y-%m-%d %H:%M\")>timedelta(minutes=0)):\n",
    "                if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 13:40',\"%Y-%m-%d %H:%M\")<timedelta(minutes=0)):\n",
    "                    la_t.append('1')\n",
    "                else:\n",
    "                    la_t.append('0')\n",
    "        else:\n",
    "             la_t.append('0')\n",
    "    else:\n",
    "        if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 11:16',\"%Y-%m-%d %H:%M\")>timedelta(minutes=0)):\n",
    "            if (datetime.strptime((test['DateTime'][i][:16]),\"%Y-%m-%d  %H:%M\")-datetime.strptime('2019-10-29 14:32',\"%Y-%m-%d %H:%M\")<timedelta(minutes=0)):\n",
    "                 la_t.append('1')\n",
    "            else:\n",
    "                 la_t.append('0')\n",
    "        else:\n",
    "               la_t.append('0')\n",
    "            \n",
    "     #test=pd.concat([test,la_t],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(la_t, columns = ['lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.concat([test,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17=all_data[all_data['machiine']=='IP17']\n",
    "IP18=all_data[all_data['machiine']=='IP18']\n",
    "IP19=all_data[all_data['machiine']=='IP19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17_FOURIER=IP17.iloc[:,63:]\n",
    "IP18_FOURIER=IP18.iloc[:,63:]\n",
    "IP19_FOURIER=IP19.iloc[:,63:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17t=test[test['machiine']=='IP17']\n",
    "IP18t=test[test['machiine']=='IP18']\n",
    "IP19t=test[test['machiine']=='IP19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP17t_FOURIER=IP17t.iloc[:,63:]\n",
    "IP18t_FOURIER=IP18t.iloc[:,63:]\n",
    "IP19t_FOURIER=IP19t.iloc[:,63:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t7=IP17t_FOURIER.drop(columns='lab')\n",
    "y_t7=IP17t_FOURIER['lab']\n",
    "X_t8=IP18t_FOURIER.drop(columns='lab')\n",
    "y_t8=IP18t_FOURIER['lab']\n",
    "X_t9=IP19t_FOURIER.drop(columns='lab')\n",
    "y_t9=IP19t_FOURIER['lab']\n",
    "X_7=IP17_FOURIER.drop(columns='lab')\n",
    "y_7=IP17_FOURIER['lab']\n",
    "X_8=IP18_FOURIER.drop(columns='lab')\n",
    "y_8=IP18_FOURIER['lab']\n",
    "X_9=IP19_FOURIER.drop(columns='lab')\n",
    "y_9=IP19_FOURIER['lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.concat([y_7,y_8,y_9,y_t7,y_t8,y_t9],axis=0)\n",
    "X=pd.concat([X_7,X_8,X_9,X_t7,X_t8,X_t9],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1=pd.concat([pd.concat([X_7,y_7],axis=1), pd.concat([X_t7,y_t7],axis=1)],axis=0)\n",
    "temp2=pd.concat([pd.concat([X_8,y_8],axis=1), pd.concat([X_t8,y_t8],axis=1)],axis=0)\n",
    "temp3=pd.concat([pd.concat([X_9,y_9],axis=1), pd.concat([X_t9,y_t9],axis=1)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=temp1[temp1['lab']=='0'].sample(n=15000,replace=True)\n",
    "a2=temp1[temp1['lab']=='1'].sample(n=15000,replace=True)\n",
    "b1=temp2[temp2['lab']=='0'].sample(n=15000,replace=True)\n",
    "b2=temp2[temp2['lab']=='1'].sample(n=15000,replace=True)\n",
    "c1=temp3[temp3['lab']=='0'].sample(n=30000,replace=True)\n",
    "c2=temp3[temp3['lab']=='1'].sample(n=30000,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.concat([X,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61498\n",
      "1696\n"
     ]
    }
   ],
   "source": [
    "print(len(y[y=='0']))\n",
    "print(len(y[y=='1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1=temp[temp['lab']=='0'].sample(n=61000,replace=True)\n",
    "S2=temp[temp['lab']=='1'].sample(n=80000,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS=pd.concat([a1,a2,c1,c2,b1,b2],axis=0)\n",
    "fx=SS.drop(columns='lab')\n",
    "fy=SS['lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all 頻遇 data over sampling 1:1 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(fx, fy, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def xg_f1(y,t):\n",
    "    t = t.get_label()\n",
    "    y_bin = [1. if y_cont > 0.5 else 0. for y_cont in y] # binaryzing your output\n",
    "    return 'f1',f1_score(t,y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\ttrain-auc:0.997807\tvalid-auc:0.995279\n",
      "[1]\ttrain-auc:0.999943\tvalid-auc:0.998804\n",
      "[2]\ttrain-auc:0.999999\tvalid-auc:0.999533\n",
      "[3]\ttrain-auc:0.999999\tvalid-auc:0.99979\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.999897\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.999925\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999955\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999972\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999977\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999978\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19610 fp:   238\n",
      "fn:     2 tp: 19750\n",
      "\n",
      "*** better f-score 0.9939607448414696\n",
      "max_depth :  30  colsample_bytree :  0.6  eta :  0.6  \n",
      "\n",
      "[0]\ttrain-auc:0.99901\tvalid-auc:0.995627\n",
      "[1]\ttrain-auc:0.999874\tvalid-auc:0.99861\n",
      "[2]\ttrain-auc:0.999972\tvalid-auc:0.999388\n",
      "[3]\ttrain-auc:1\tvalid-auc:0.999728\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.99981\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.999853\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999898\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999901\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999905\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999944\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19632 fp:   216\n",
      "fn:     2 tp: 19750\n",
      "\n",
      "*** better f-score 0.9945113046981218\n",
      "max_depth :  30  colsample_bytree :  1.0  eta :  0.39999999999999997  \n",
      "\n",
      "[0]\ttrain-auc:0.998793\tvalid-auc:0.995597\n",
      "[1]\ttrain-auc:0.999909\tvalid-auc:0.998701\n",
      "[2]\ttrain-auc:0.999998\tvalid-auc:0.999514\n",
      "[3]\ttrain-auc:1\tvalid-auc:0.999827\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.999899\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.999946\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999971\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999979\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999978\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999977\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19615 fp:   233\n",
      "fn:     2 tp: 19750\n",
      "\n",
      "[0]\ttrain-auc:0.997434\tvalid-auc:0.994251\n",
      "[1]\ttrain-auc:0.999837\tvalid-auc:0.99856\n",
      "[2]\ttrain-auc:0.999977\tvalid-auc:0.999451\n",
      "[3]\ttrain-auc:0.999998\tvalid-auc:0.999746\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.999844\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.999899\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999908\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.99994\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999971\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999971\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19620 fp:   228\n",
      "fn:     2 tp: 19750\n",
      "\n",
      "[0]\ttrain-auc:0.995278\tvalid-auc:0.992553\n",
      "[1]\ttrain-auc:0.999597\tvalid-auc:0.998384\n",
      "[2]\ttrain-auc:0.999896\tvalid-auc:0.999172\n",
      "[3]\ttrain-auc:0.999966\tvalid-auc:0.999641\n",
      "[4]\ttrain-auc:0.999968\tvalid-auc:0.999827\n",
      "[5]\ttrain-auc:0.999971\tvalid-auc:0.999888\n",
      "[6]\ttrain-auc:0.999998\tvalid-auc:0.99992\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999932\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999945\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999958\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19617 fp:   231\n",
      "fn:     0 tp: 19752\n",
      "\n",
      "[0]\ttrain-auc:0.998793\tvalid-auc:0.995597\n",
      "[1]\ttrain-auc:0.999876\tvalid-auc:0.998737\n",
      "[2]\ttrain-auc:0.999983\tvalid-auc:0.9995\n",
      "[3]\ttrain-auc:0.999999\tvalid-auc:0.999785\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.999894\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.99994\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999956\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999974\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999977\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999979\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19629 fp:   219\n",
      "fn:     2 tp: 19750\n",
      "\n",
      "[0]\ttrain-auc:0.997294\tvalid-auc:0.994439\n",
      "[1]\ttrain-auc:0.999498\tvalid-auc:0.998298\n",
      "[2]\ttrain-auc:0.999914\tvalid-auc:0.999202\n",
      "[3]\ttrain-auc:0.999993\tvalid-auc:0.999573\n",
      "[4]\ttrain-auc:0.999999\tvalid-auc:0.99975\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.999888\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999912\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999941\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999975\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999977\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19608 fp:   240\n",
      "fn:     0 tp: 19752\n",
      "\n",
      "[0]\ttrain-auc:0.997894\tvalid-auc:0.994673\n",
      "[1]\ttrain-auc:0.999942\tvalid-auc:0.999131\n",
      "[2]\ttrain-auc:0.999984\tvalid-auc:0.999667\n",
      "[3]\ttrain-auc:1\tvalid-auc:0.99977\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.999864\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.999926\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999939\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999974\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999985\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999987\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19645 fp:   203\n",
      "fn:     3 tp: 19749\n",
      "\n",
      "*** better f-score 0.9948116058835382\n",
      "max_depth :  30  colsample_bytree :  0.5  eta :  0.5  \n",
      "\n",
      "[0]\ttrain-auc:0.998703\tvalid-auc:0.995444\n",
      "[1]\ttrain-auc:0.999853\tvalid-auc:0.998601\n",
      "[2]\ttrain-auc:0.999996\tvalid-auc:0.999302\n",
      "[3]\ttrain-auc:1\tvalid-auc:0.999666\n",
      "[4]\ttrain-auc:1\tvalid-auc:0.999761\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.999851\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999908\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.999947\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999958\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.999968\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19630 fp:   218\n",
      "fn:     2 tp: 19750\n",
      "\n",
      "[0]\ttrain-auc:0.9969\tvalid-auc:0.993989\n",
      "[1]\ttrain-auc:0.999856\tvalid-auc:0.998603\n",
      "[2]\ttrain-auc:0.999942\tvalid-auc:0.999533\n",
      "[3]\ttrain-auc:0.999971\tvalid-auc:0.999749\n",
      "[4]\ttrain-auc:0.999999\tvalid-auc:0.999854\n",
      "[5]\ttrain-auc:1\tvalid-auc:0.999927\n",
      "[6]\ttrain-auc:1\tvalid-auc:0.999947\n",
      "[7]\ttrain-auc:1\tvalid-auc:0.99994\n",
      "[8]\ttrain-auc:1\tvalid-auc:0.999963\n",
      "[9]\ttrain-auc:1\tvalid-auc:0.99997\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 19660 fp:   188\n",
      "fn:     0 tp: 19752\n",
      "\n",
      "*** better f-score 0.9952635291746448\n",
      "max_depth :  25  colsample_bytree :  0.6  eta :  0.5  \n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_model =  XGBClassifier()\n",
    "## parameters to be tuned\n",
    "tune_dic = OrderedDict()\n",
    "\n",
    "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
    "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
    "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
    "\n",
    "best_params = dict()\n",
    "best_f_score = -1\n",
    "\n",
    "import itertools\n",
    "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
    "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
    "\n",
    "columns=[*tune_dic.keys()]+['F Score']\n",
    "\n",
    "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
    "\n",
    "for i in range(len(search)): ## len(search)\n",
    "    \n",
    "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "        param[key]=val\n",
    "\n",
    "    print()    \n",
    "    #f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
    "    #do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    \n",
    "    evallist  = [(dtrain,'train'), (dvalid,'valid')]\n",
    "    \n",
    "    model = xgb.train( param, dtrain, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(dvalid)\n",
    "    labels = dvalid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY=='1')\n",
    "    act_neg=dvalid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "\n",
    "    \n",
    "    \n",
    "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
    "    results.loc[i,'F Score']=f_score\n",
    "    \n",
    "    if f_score > best_f_score:\n",
    "        best_model = model\n",
    "        best_f_score = f_score\n",
    "        print('\\n*** better f-score',f_score)\n",
    "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
    "            best_params[key]=val        \n",
    "            print(key,': ',val,' ',end='')\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, trainY, validY = train_test_split(X, y, random_state = 7, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train, label=trainY)\n",
    "dvalid = xgb.DMatrix(valid, label=validY)\n",
    "#dtest = xgb.DMatrix(test, label=testY)\n",
    "\n",
    "## fixed parameters\n",
    "scale_pos_weight = sum(trainY=='0')/sum(trainY=='1')  \n",
    "num_rounds=10 # number of boosting iterations\n",
    "\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, ## unbalanced dataset\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc', \n",
    "         'scale_pos_weight':scale_pos_weight}\n",
    "\n",
    "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
    "    ## train with given fixed and variable parameters\n",
    "    ## and report performance on validation dataset\n",
    "    evallist  = [(train,train_s), (valid,valid_s)]\n",
    "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
    "                      evals=evallist )    \n",
    "    preds = model.predict(valid)\n",
    "    labels = valid.get_label()\n",
    "      \n",
    "    act_pos=sum(validY==1)\n",
    "    act_neg=valid.num_row()-act_pos\n",
    "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "    false_neg=act_pos-true_pos\n",
    "    true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "    print('\\nconfusion matrix')\n",
    "    print('----------------')\n",
    "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "    return(f_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(S2['lab']=='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=pd.concat([y_7,y_t7],axis=0) #頻率 train 17、18 test 19\n",
    "X1=pd.concat([X_7,X_t7],axis=0)\n",
    "y2=pd.concat([y_9,y_t9],axis=0)\n",
    "X2=pd.concat([X_9,X_t9],axis=0)\n",
    "y3=pd.concat([y_8,y_t8],axis=0)\n",
    "X3=pd.concat([X_8,X_t8],axis=0)\n",
    "AX1=pd.concat([a1,a2],axis=0)\n",
    "AX2=pd.concat([b1,b2],axis=0)\n",
    "AX3=pd.concat([c1,c2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST tarin 17、18 、19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(X1, label=y1)\n",
    "all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 17371 fp:   716\n",
      "fn:     0 tp:  1606\n",
      "0.8177189409368636\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y1=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(X2, label=y2)\n",
    "all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 22919 fp:    21\n",
      "fn:     0 tp:    51\n",
      "0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y2=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "\n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(X3, label=y3)\n",
    "all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 20469 fp:     2\n",
      "fn:     0 tp:    39\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y3=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.75) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.75) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(X, label=y)\n",
    "all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 60759 fp:   739\n",
      "fn:     0 tp:  1696\n",
      "0.8211086903897361\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST ALL DATA SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae14e8cea932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "St=temp[temp['lab']=='0'].sample(n=5000,replace=True)\n",
    "St2=temp[temp['lab']=='1'].sample(n=1000,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSt=pd.concat([St,St2],axis=0)\n",
    "ffx=SSt.drop(columns='lab')\n",
    "ffy=SSt['lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = xgb.DMatrix(ffx, label=ffy)\n",
    "all = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn:  4100 fp:   204\n",
      "fn:  1677 tp:    19\n",
      "0.0198019801980198\n"
     ]
    }
   ],
   "source": [
    "#best_model.predict(aaa)\n",
    "preds = best_model.predict(aaa)\n",
    "labels = aaa.get_label()\n",
    "      \n",
    "act_pos=sum(y=='1')\n",
    "act_neg=aaa.num_row()-act_pos\n",
    "\n",
    "\n",
    "true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
    "false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
    "false_neg=act_pos-true_pos\n",
    "true_neg=act_neg-false_pos\n",
    "    \n",
    "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
    "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
    "    ## F-score with beta=1\n",
    "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
    "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
    "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
    "    \n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "f_score = 2*precision*recall/(precision+recall)  \n",
    "    \n",
    "print('\\nconfusion matrix')\n",
    "print('----------------')\n",
    "print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
    "print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
